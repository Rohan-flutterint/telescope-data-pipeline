{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82c99beb-6776-4c35-9328-9c738883ce90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SPACE DATA DISTRIBUTED SYSTEM DEMO\n",
    "# Unity Catalog Safe â€“ No DBFS (Just for the demo )\n",
    "# ============================================\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import random\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS space_db\")\n",
    "spark.sql(\"USE space_db\")\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS bronze_space\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS silver_space\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS gold_space\")\n",
    "\n",
    "# ============================================\n",
    "# 1. Generate Mock Telescope Data (Batch)\n",
    "# ============================================\n",
    "\n",
    "num_rows = 1000000\n",
    "\n",
    "data = []\n",
    "for i in range(num_rows):\n",
    "    lat = random.uniform(-90, 90)\n",
    "    lon = random.uniform(-180, 180)\n",
    "\n",
    "    # create sparse feature map (2 features per row)\n",
    "    features = {\n",
    "        random.randint(1,1000): random.random(),\n",
    "        random.randint(1,1000): random.random()\n",
    "    }\n",
    "\n",
    "    data.append((i, lat, lon, features))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"obs_id\", LongType()),\n",
    "    StructField(\"lat\", DoubleType()),\n",
    "    StructField(\"lon\", DoubleType()),\n",
    "    StructField(\"features\", MapType(IntegerType(), DoubleType()))\n",
    "])\n",
    "\n",
    "bronze_df = spark.createDataFrame(data, schema) \\\n",
    "    .withColumn(\"timestamp\", current_timestamp())\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS bronze_space\")\n",
    "\n",
    "bronze_df.write.format(\"delta\").saveAsTable(\"bronze_space\")\n",
    "\n",
    "print(\"======================================\")\n",
    "print(\"Bronze table created\")\n",
    "print(\"======================================\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2. Spatial Partitioning (Octant Example)\n",
    "# ============================================\n",
    "\n",
    "def compute_partition(lat, lon):\n",
    "    if lat >= 0 and lon >= 0:\n",
    "        return \"P0\"\n",
    "    elif lat >= 0 and lon < 0:\n",
    "        return \"P1\"\n",
    "    elif lat < 0 and lon >= 0:\n",
    "        return \"P2\"\n",
    "    else:\n",
    "        return \"P3\"\n",
    "\n",
    "partition_udf = udf(compute_partition, StringType())\n",
    "\n",
    "bronze_df = spark.table(\"bronze_space\") \\\n",
    "    .withColumn(\"partition_id\", partition_udf(\"lat\",\"lon\"))\n",
    "\n",
    "\n",
    "\n",
    "bronze_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"bronze_space\")\n",
    "\n",
    "print(\"Spatial partitioning added\")\n",
    "print(\"======================================\")\n",
    "\n",
    "# ============================================\n",
    "# 3. Sparse Triplet Conversion (Silver Layer)\n",
    "# ============================================\n",
    "\n",
    "silver_df = bronze_df.select(\n",
    "    \"obs_id\",\n",
    "    \"timestamp\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"partition_id\",\n",
    "    explode(\"features\").alias(\"feature_id\",\"value\")\n",
    ")\n",
    "\n",
    "silver_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .partitionBy(\"partition_id\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"silver_space\")\n",
    "\n",
    "print(\"Silver table created (sparse triplets)\")\n",
    "print(\"======================================\")\n",
    "\n",
    "# ============================================\n",
    "# 4. Optimize Layout\n",
    "# ============================================\n",
    "\n",
    "spark.sql(\"OPTIMIZE silver_space ZORDER BY (feature_id)\")\n",
    "\n",
    "print(\"Optimization complete\")\n",
    "print(\"======================================\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 5. Gold Layer (Aggregations)\n",
    "# ============================================\n",
    "\n",
    "gold_df = spark.table(\"silver_space\") \\\n",
    "    .groupBy(\"partition_id\",\"feature_id\") \\\n",
    "    .agg(\n",
    "        avg(\"value\").alias(\"avg_value\"),\n",
    "        count(\"*\").alias(\"observation_count\")\n",
    "    )\n",
    "\n",
    "gold_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"gold_space\")\n",
    "\n",
    "print(\"Gold table created\")\n",
    "print(\"======================================\")\n",
    "\n",
    "# ============================================\n",
    "# 6. Demo Queries\n",
    "# ============================================\n",
    "\n",
    "print(\"Top Features by Average Value:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT partition_id, feature_id, avg_value\n",
    "FROM gold_space\n",
    "ORDER BY avg_value DESC\n",
    "LIMIT 20\n",
    "\"\"\").show()\n",
    "print(\"======================================\")\n",
    "\n",
    "print(\"Sample bronze Sparse Records:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM bronze_space\n",
    "LIMIT 20\n",
    "\"\"\").show()\n",
    "print(\"======================================\")\n",
    "\n",
    "\n",
    "# spark.sql(\"\"\"\n",
    "# EXPLAIN\n",
    "# SELECT *\n",
    "# FROM silver_space\n",
    "# WHERE partition_id = 'P0'\n",
    "# AND feature_id = 500\n",
    "# \"\"\").show(truncate=False)\n",
    "# print(\"======================================\")\n",
    "\n",
    "# spark.sql(\"DESCRIBE DETAIL silver_space\").show(truncate=False)\n",
    "\n",
    "# print(\"======================================\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Telescope Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
